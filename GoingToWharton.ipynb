{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shashwat26Bhatnagar/BitTanh_Action_Function/blob/main/GoingToWharton.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DDpV7Ncd9NNM",
        "outputId": "a6732b68-73cb-41fd-878a-779e174d11b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  swig4.0\n",
            "Suggested packages:\n",
            "  swig-doc swig-examples swig4.0-examples swig4.0-doc\n",
            "The following NEW packages will be installed:\n",
            "  swig swig4.0\n",
            "0 upgraded, 2 newly installed, 0 to remove and 45 not upgraded.\n",
            "Need to get 1,116 kB of archives.\n",
            "After this operation, 5,542 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 swig4.0 amd64 4.0.2-1ubuntu1 [1,110 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/universe amd64 swig all 4.0.2-1ubuntu1 [5,632 B]\n",
            "Fetched 1,116 kB in 1s (1,028 kB/s)\n",
            "Selecting previously unselected package swig4.0.\n",
            "(Reading database ... 121753 files and directories currently installed.)\n",
            "Preparing to unpack .../swig4.0_4.0.2-1ubuntu1_amd64.deb ...\n",
            "Unpacking swig4.0 (4.0.2-1ubuntu1) ...\n",
            "Selecting previously unselected package swig.\n",
            "Preparing to unpack .../swig_4.0.2-1ubuntu1_all.deb ...\n",
            "Unpacking swig (4.0.2-1ubuntu1) ...\n",
            "Setting up swig4.0 (4.0.2-1ubuntu1) ...\n",
            "Setting up swig (4.0.2-1ubuntu1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n"
          ]
        }
      ],
      "source": [
        "!apt-get install swig"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8LUtuzCsmH1n",
        "outputId": "9dba834a-508c-4493-c1d4-2ac553691a8a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cp: cannot stat 'kaggle.json': No such file or directory\n"
          ]
        }
      ],
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ga9zKPi-mB1E",
        "outputId": "90fede6f-0d2e-4f11-fab7-3ac623d54b3b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/kaggle\", line 5, in <module>\n",
            "    from kaggle.cli import main\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/kaggle/__init__.py\", line 23, in <module>\n",
            "    api.authenticate()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/kaggle/api/kaggle_api_extended.py\", line 403, in authenticate\n",
            "    raise IOError('Could not find {}. Make sure it\\'s located in'\n",
            "OSError: Could not find kaggle.json. Make sure it's located in /root/.kaggle. Or use the environment method.\n"
          ]
        }
      ],
      "source": [
        "!kaggle datasets download -d salader/dogs-vs-cats"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k5GBTS4nmayj",
        "outputId": "1cc1f1d9-f460-478c-9c59-03297bb61312",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/dogs-vs-cats.zip'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-4f800be457d7>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mzipfile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mzip_ref\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzipfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/dogs-vs-cats.zip'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mzip_ref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextractall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mzip_ref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/zipfile.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, file, mode, compression, allowZip64, compresslevel, strict_timestamps)\u001b[0m\n\u001b[1;32m   1249\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1250\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1251\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilemode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1252\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1253\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mfilemode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodeDict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/dogs-vs-cats.zip'"
          ]
        }
      ],
      "source": [
        "import zipfile\n",
        "zip_ref = zipfile.ZipFile('/content/dogs-vs-cats.zip','r')\n",
        "zip_ref.extractall('/content')\n",
        "zip_ref.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1IJqQLLy9aZ5",
        "outputId": "7495ce7f-d3cf-42d5-a2e1-5ec5de499488",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing approx.c\n"
          ]
        }
      ],
      "source": [
        "%%writefile approx.c\n",
        "/* File : approx.c */\n",
        "\n",
        "    #include <math.h>\n",
        "    #include <stdio.h>\n",
        "\n",
        "float custom_tanh(float number) {\n",
        "    float x_square = pow(number, 2);\n",
        "    // printf(\"%f\\n\",x_square);\n",
        "    float x_double = 2 * number;\n",
        "    float y;\n",
        "\n",
        "    float pos = x_square + x_double;\n",
        "    float neg = pos + 2;\n",
        "\n",
        "    long i, j, k;\n",
        "    i = *(long *) &pos;\n",
        "    j = *(long *) &neg;\n",
        "\n",
        "    // Take 2's complement of j\n",
        "    // i = ~i + 1;\n",
        "\n",
        "    // Perform bitwise addition\n",
        "    k = i-j;\n",
        "\n",
        "    // Add the bias to the result\n",
        "    k = k + 0x3f811a7a;\n",
        "\n",
        "\n",
        "    // Convert back to float\n",
        "    y = *(float *) &k;\n",
        "\n",
        "    return y;\n",
        "}\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EIEuzuzi9f_q"
      },
      "outputs": [],
      "source": [
        "%%writefile approx.i\n",
        "/* approx.i */\n",
        "%module approx\n",
        "%{\n",
        "    extern float custom_tanh(float number);\n",
        "\n",
        "\n",
        "%}\n",
        "\n",
        "\n",
        "extern float custom_tanh(float number);\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "feErzHMv9iqa"
      },
      "outputs": [],
      "source": [
        "!python3-config --cflags"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pFre5MYV9mVh"
      },
      "outputs": [],
      "source": [
        "import sysconfig\n",
        "\n",
        "print(sysconfig.get_paths()['include'])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dxXl1Z4j9pDl"
      },
      "outputs": [],
      "source": [
        "!swig -python  approx.i\n",
        "!gcc -c approx.c approx_wrap.c \\\n",
        "  -I/usr/include/python3.10 -fPIC\n",
        "!ld -shared approx.o approx_wrap.o -o _approx.so\n",
        "\n",
        "\n",
        "!swig -python approx.i\n",
        "!gcc -c -fPIC approx.c approx_wrap.c -I/usr/include/python3.10\n",
        "!ld -shared approx.o approx_wrap.o -o _approx.so\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uk_RxPnU9tOg"
      },
      "outputs": [],
      "source": [
        "import approx\n",
        "import numpy as np\n",
        "import time\n",
        "from multiprocessing import Process , Array"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GXJ9Ph3E9weX"
      },
      "outputs": [],
      "source": [
        "def process_element(arr, result, index):\n",
        "  result[index]=approx.custom_tanh(arr[index])\n",
        "def parallel_compute(arr):\n",
        "  result = Array('d',len(arr))#creating a shared libarry for processes\n",
        "  #creating start processes for each element\n",
        "  processes=[]\n",
        "  for i in range(len(arr)):\n",
        "    process=Process(target=process_element , args=(arr,result,i))\n",
        "    process.start()\n",
        "    processes.append(process)\n",
        "\n",
        "  #wait for all process to complete\n",
        "  for process in processes:\n",
        "    process.join()\n",
        "\n",
        "  #convert the shared array to Numpy array and return it\n",
        "  return np.frombuffer(result.get_obj())\n",
        "\n",
        "def BitTanh(arr):\n",
        "  result_arr= parallel_compute(arr)\n",
        "  return result_arr\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g17SmJSWCWnb"
      },
      "outputs": [],
      "source": [
        "data= np.array([00.53,0.032,0.02236,0.28868])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sbaDXwVS_XpJ"
      },
      "outputs": [],
      "source": [
        "%%timeit\n",
        "BitTanh(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c-3ctcW1CEJw"
      },
      "outputs": [],
      "source": [
        "%%timeit\n",
        "np.tanh(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ULdUDfVXf20x"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SdHJzQwQl4wv"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import approx\n",
        "from multiprocessing import Pool\n",
        "\n",
        "def custom_activation(x):\n",
        "    def custom_activation_function(x):\n",
        "        # Example activation function using math.tanh()\n",
        "        return approx.custom_tanh(x)\n",
        "\n",
        "    # for i,xi in x.flatten():\n",
        "    #   print(type(xi))\n",
        "    #   xi=xi.detach().numpy()\n",
        "    #   result_flattened_image=custom_activation_function(xi)\n",
        "    # Iterate through each element of the input tensor x and apply the custom activation function\n",
        "    result_flattened_image=[]\n",
        "    for xi in x.flatten():\n",
        "      xa=float(xi)\n",
        "      result_flattened_image.append(approx.custom_tanh(xa))\n",
        "\n",
        "    #result_flattened_image = [{xa:=float(xi),custom_activation_function(xa)} for xi in x.flatten()]\n",
        "\n",
        "\n",
        "    #result_image = np.array(result_flattened_image).reshape(x.shape)\n",
        "    #print(result_flattened_image)\n",
        "    # result_image = list(map(int, result_flattened_image))\n",
        "    # result_image = result_flattened_image.astype(np.float32)\n",
        "    return result_flattened_image\n",
        "# eg = torch.tensor([1.,2.], requires_grad = True)\n",
        "# custom_activation(eg)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SgAp3NM9UH9r"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fe0w-neBYelN"
      },
      "outputs": [],
      "source": [
        "# import numpy as np\n",
        "# from multiprocessing import Pool\n",
        "\n",
        "# # Define your custom activation function\n",
        "# def custom_activation(x):\n",
        "#     # Example custom activation function\n",
        "#     return x * 2  # Double the input value\n",
        "\n",
        "# # Function to apply activation function to a chunk of image array\n",
        "# def apply_activation_to_chunk(chunk):\n",
        "#     return custom_activation(chunk)\n",
        "\n",
        "# # Example 3D NumPy array representing an image\n",
        "# image = np.random.rand(100, 100, 1)  # Example image with dimensions (height, width, channels)\n",
        "\n",
        "# # Define the chunk size (adjust as needed)\n",
        "# chunk_size = 10\n",
        "\n",
        "# # Split the image array into smaller chunks along the height dimension\n",
        "# chunks = [image[i:i+chunk_size] for i in range(0, image.shape[0], chunk_size)]\n",
        "\n",
        "# # Create a multiprocessing pool\n",
        "# with Pool() as pool:\n",
        "#     # Apply the activation function to each chunk in parallel\n",
        "#     processed_chunks = pool.map(apply_activation_to_chunk, chunks)\n",
        "\n",
        "# # Combine the processed chunks to reconstruct the processed image array\n",
        "# processed_image = np.concatenate(processed_chunks)\n",
        "\n",
        "# # Processed image is now ready for further use"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QF-cQ8pQLHuD"
      },
      "outputs": [],
      "source": [
        "!pip install dill"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uYiOrhNkC6m-"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import csv\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import dill as pickle\n",
        "\n",
        "# Define your custom activation function\n",
        "class CustomActivation(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CustomActivation, self).__init__()\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        a = custom_activation(x)\n",
        "        return a  # Example of a custom activation function\n",
        "\n",
        "# Define your custom model\n",
        "class CustomModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CustomModel, self).__init__()\n",
        "        self.fc1 = nn.Linear(784, 512)  # Input size: 28x28 = 784\n",
        "        self.fc2 = nn.Linear(512, 256)\n",
        "        self.fc3 = nn.Linear(256, 128)\n",
        "        self.fc4 = nn.Linear(128, 64)   # Add an extra layer with 64 units\n",
        "        self.fc5 = nn.Linear(64, 2)     # Output size: 2 for 2 classes (cat and dog)\n",
        "        self.custom_activation = CustomActivation()  # Custom activation function\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 784)  # Flatten the input images\n",
        "        x = self.custom_activation(self.fc1(x))  # Applying custom activation to fc1\n",
        "        x=torch.as_tensor(x,dtype=torch.float32)\n",
        "\n",
        "\n",
        "        x = x.view(-1, 512)\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = F.relu(self.fc3(x))\n",
        "        x = F.relu(self.fc4(x))\n",
        "        x = self.fc5(x)\n",
        "        return F.log_softmax(x, dim=1)  # Apply log softmax for classification\n",
        "\n",
        "\n",
        "# Define a custom dataset class\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, data_folder, transform=None):\n",
        "        self.data_folder = data_folder\n",
        "        self.transform = transform\n",
        "        self.image_paths = self.get_image_paths()\n",
        "\n",
        "    def get_image_paths(self):\n",
        "        image_paths = []\n",
        "        for root, _, files in os.walk(self.data_folder):\n",
        "            for file in files:\n",
        "                if file.endswith('.jpg') or file.endswith('.png'):\n",
        "                    image_paths.append(os.path.join(root, file))\n",
        "        return image_paths\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image_path = self.image_paths[idx]\n",
        "        image = Image.open(image_path).convert('L')  # Convert image to grayscale\n",
        "        if self.transform:\n",
        "           image = self.transform(image)\n",
        "        label = 0 if 'cat' in os.path.dirname(image_path) else 1  # Inferred label based on directory structure\n",
        "        return image, label\n",
        "\n",
        "\n",
        "# Load and preprocess the data\n",
        "def load_data(data_folder, batch_size=64, test_size=0.2, random_state=42):\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((28, 28)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5,), (0.5,))\n",
        "    ])\n",
        "\n",
        "    dataset = CustomDataset(data_folder, transform=transform)\n",
        "\n",
        "    # Split the dataset into train and test sets\n",
        "    train_set, test_set = train_test_split(dataset, test_size=test_size, random_state=random_state)\n",
        "\n",
        "    # Create DataLoader objects\n",
        "    train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
        "    test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    return train_loader, test_loader\n",
        "\n",
        "# Train the model\n",
        "def train_model(model, train_loader, optimizer, criterion, epochs):\n",
        "    model.train()\n",
        "    losses = []\n",
        "    for epoch in range(epochs):\n",
        "        running_loss = 0.0\n",
        "        for data, target in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            output = model(data)\n",
        "            loss = criterion(output, target)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "        epoch_loss = running_loss / len(train_loader)\n",
        "        losses.append(epoch_loss)\n",
        "        print('Epoch %d, Loss: %.4f' % (epoch+1, epoch_loss))\n",
        "    return losses\n",
        "\n",
        "# Test the model\n",
        "def test_model(model, test_loader):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            output = model(data)\n",
        "            _, predicted = torch.max(output.data, 1)\n",
        "            total += target.size(0)\n",
        "            correct += (predicted == target).sum().item()\n",
        "    accuracy = 100 * correct / total\n",
        "    print('Accuracy on test set: %d %%' % accuracy)\n",
        "    return accuracy\n",
        "\n",
        "# Load data\n",
        "train_loader, test_loader = load_data('/content/train')\n",
        "\n",
        "# Define and train the model\n",
        "model = CustomModel()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "epochs = 25\n",
        "losses = train_model(model, train_loader, optimizer, criterion, epochs)\n",
        "accuracy = test_model(model, test_loader)\n",
        "\n",
        "# Plot loss vs epochs\n",
        "plt.plot(range(1, epochs+1), losses)\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Loss vs Epochs')\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# Plot accuracy vs epochs\n",
        "plt.plot(range(1, epochs+1), [accuracy]*epochs)\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy (%)')\n",
        "plt.title('Accuracy vs Epochs')\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# Save the current figure\n",
        "plt.savefig('output_window.png')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fkDPa1hF9syZ"
      },
      "outputs": [],
      "source": [
        "# Plot loss vs epochs\n",
        "plt.plot(range(1, epochs+1), losses, marker='o')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Loss vs Epochs')\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# Plot accuracy vs epochs\n",
        "plt.plot(range(1, epochs+1), [accuracy]*epochs, linestyle='--', label='Test Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy (%)')\n",
        "plt.title('Accuracy vs Epochs')\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cg3IFUR-0yia"
      },
      "outputs": [],
      "source": [
        "# Save the model\n",
        "torch.save(model.state_dict(), 'custom_model.pth')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R0YQjXd919zS"
      },
      "outputs": [],
      "source": [
        "def predict_image(model, image_path):\n",
        "    # Open the image\n",
        "    image = Image.open(image_path).convert('L')  # Convert image to grayscale\n",
        "    # Preprocess the image\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((28, 28)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5,), (0.5,))\n",
        "    ])\n",
        "    image_tensor = transform(image).unsqueeze(0)  # Add batch dimension\n",
        "\n",
        "    # Predict the label\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        output = model(image_tensor)\n",
        "        _, predicted = torch.max(output, 1)\n",
        "\n",
        "    # Display the image and prediction\n",
        "    plt.imshow(image, cmap='gray')\n",
        "    plt.axis('off')\n",
        "    if predicted.item() == 0:\n",
        "        print(\"Predicted: Cat\")\n",
        "    else:\n",
        "        print(\"Predicted: Dog\")\n",
        "    plt.show()\n",
        "\n",
        "# Example usage\n",
        "image_path = 'example_img3.png'\n",
        "predict_image(model, image_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ds7HT-mcAV52"
      },
      "outputs": [],
      "source": [
        "!jupyter notebook --NotebookApp.iopub_data_rate_limit=10000000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m7rf_MIT5Ein"
      },
      "outputs": [],
      "source": [
        "test_model(model, test_loader)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}